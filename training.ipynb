{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model import OwlNet\n",
    "\n",
    "\n",
    "def loss_func(batch, similarity_threshold=0.65, margin=0.0):\n",
    "    batch_size = batch.shape[0]\n",
    "    batch = F.normalize(batch, p=2, dim=1)  # Normalize embeddings for cosine similarity\n",
    "    \n",
    "    # Compute cosine similarity matrix\n",
    "    similarity_matrix = torch.mm(batch, batch.T)  # Shape: (batch_size, batch_size)\n",
    "    \n",
    "    # Mask out self-similarity\n",
    "    mask = torch.eye(batch_size, device=batch.device).bool()\n",
    "    similarity_matrix.masked_fill_(mask, -1)  # Set diagonal to -1 so it's not considered a neighbor\n",
    "    \n",
    "    # Find nearest neighbors based on similarity threshold\n",
    "    positive_mask = similarity_matrix >= similarity_threshold  # Positive pairs\n",
    "    negative_mask = similarity_matrix < similarity_threshold  # Negative pairs\n",
    "    \n",
    "    # Loss computation\n",
    "    positive_loss = (1 - similarity_matrix)[positive_mask].mean() if positive_mask.any() else torch.tensor(0.0, device=batch.device)\n",
    "    negative_loss = F.relu(similarity_matrix[negative_mask] - margin).mean() if negative_mask.any() else torch.tensor(0.0, device=batch.device)\n",
    "    \n",
    "\n",
    "    loss = positive_loss + negative_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_data\n",
    "from data_utils import display_melspec\n",
    "\n",
    "\n",
    "drop = 0.0\n",
    "embed_sz = 64\n",
    "epochs = 100\n",
    "# lr = 2e-6\n",
    "lr = 5e-6\n",
    "batch_sz = 512\n",
    "debug = False\n",
    "spec_height = 750\n",
    "\n",
    "owlet_train, owlet_test, dataset = load_data(\n",
    "    \"lotek_owl_data\",\n",
    "    train_test_split=[1.0, 0],\n",
    "    batch_sz=batch_sz,\n",
    "    debug=debug,\n",
    "    spec_height=spec_height\n",
    ")\n",
    "# owlet_train, owlet_test = load_toy_data(batch_sz=batch_sz, train_test_split=[1.0, 0])\n",
    "# show sample image\n",
    "img = next(iter(owlet_train))[0][0]\n",
    "display_melspec(img, size=(4, 4), colorbar=False)\n",
    "\n",
    "model_name = f\"model_{len(owlet_train)}.datapoints_{epochs}.epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from model import OwlNet\n",
    "\n",
    "\n",
    "owlnet = OwlNet(embed_sz, drop).cuda()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(owlnet.parameters(), betas=(0.9, 0.999), lr=lr)\n",
    "loss_function = loss_func\n",
    "for epoch in range(epochs):\n",
    "    owlnet.train()\n",
    "    for i, (train_batch, _) in enumerate(owlet_train):\n",
    "        batch_sz = train_batch.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        train_batch = train_batch.cuda()\n",
    "        embeds = owlnet(train_batch)\n",
    "        embeds = F.normalize(embeds, p=2, dim=1)  # Normalize embeddings for cosine similarity\n",
    "        loss = loss_function(embeds)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Train Epoch {epoch + 1} ({i}/{len(owlet_train)}): Loss {loss.item()}\", end=\"\\r\")\n",
    "\n",
    "torch.save(owlnet.state_dict(), f\"{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "drop = 0.0\n",
    "batch_sz = 512\n",
    "debug = False\n",
    "spec_height = 750\n",
    "embed_sz = 64\n",
    "\n",
    "model_name = \"model_3k.datapoints_100.epochs.pth\"\n",
    "owlnet_dict = torch.load(model_name)\n",
    "owlnet = OwlNet(embed_sz, drop).cuda()\n",
    "owlnet.load_state_dict(owlnet_dict)\n",
    "owlnet.eval()\n",
    "\n",
    "owlet_train, owlet_test, owlet_dataset = load_data(\n",
    "    \"lotek_owl_data\",\n",
    "    train_test_split=[1.0, 0],\n",
    "    batch_sz=batch_sz,\n",
    "    debug=debug,\n",
    "    spec_height=spec_height\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cairees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
